#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Explore-Exploit fMRI: Neuron Manuscript
Merging pomdp outputs, and all behavioral output data into a mega df
notes: Main code product is file: <behave/alldat_bandit.csv

author: jeremy hogeveen (jhogeveen@unm.edu)
last edit: March 9, 2022
"""

#%% PREAMBLE
# Importing modules for the script
import glob
import os
import pandas as pd
import numpy as np
import re
# import seaborn as sns
# import matplotlib.pyplot as plt

# setting up the filepaths
# dirs
script_dir = os.path.dirname(__file__)
base_dir = os.path.abspath(os.path.join(script_dir,'..'))
behave_dir = os.path.join(base_dir,'behave')
regressors_dir = os.path.join(base_dir,'regressors')
pomdp_dir = os.path.join(base_dir,'model_dat/pomdp_out')
pomdp_sum_dir = os.path.join(base_dir,'model_dat/pomdp_sum')
plot_dir = os.path.join(base_dir,'plots')
# filenames
eprime_behave_filename = os.path.join(behave_dir,'*-EDAT-MRI.csv')
custom_behave_filename = os.path.join(behave_dir,'*-MRITRIALINFO_ACEFMRIMEG.csv')
confound_behave_filename = os.path.join(base_dir,'fmriprep/fmriprep/*/*/*bandit*_confounds.tsv')
pomdp_filename = os.path.join(pomdp_dir,'*_mdpout.txt')
# getting the list of filenames we need to open in the series
eprime_files = glob.glob(eprime_behave_filename)
custom_files = glob.glob(custom_behave_filename)
confound_files = glob.glob(confound_behave_filename)
pomdp_files = glob.glob(pomdp_filename)
# output filename
bandit_alldat_out = os.path.join(behave_dir,'alldat_bandit.csv')
#%%

#%% Generating a plot of the behavioral task performance as a function of novel vs. best vs. worst
# Extracting the data I need
df_append = pd.DataFrame()
for i in range(0,len(eprime_files)):
    ##### Step 1: Loading the data and generating the onset and conditions we need #####
    # Pulling the participant number we want to load
    pid_wildcard = re.compile('P0..')
    cursub = pid_wildcard.findall(eprime_files[i])
    # Generating an eprime filename
    cursub_eprime_filename = [s for s in eprime_files if cursub[0] in s]
    # Generating a trial info filename
    cursub_custom_filename = [s for s in custom_files if cursub[0] in s]
    # Generating a pomdp filename
    cursub_pomdp_filename = [s for s in pomdp_files if cursub[0] in s]
    ### Reading in the data
    df = pd.read_csv(cursub_eprime_filename[0])
    df_custom = pd.read_csv(cursub_custom_filename[0])
    ### Reading in the POMDP data
    df_pomdp = pd.read_csv(cursub_pomdp_filename[0], sep='\t',header=None)
    df_pomdp = df_pomdp.dropna(axis='columns',how='all') # dropping an empty column that appears to exist in the pomdp files
    df_pomdp.columns=["pid", "Trial_pomdp", "chosenovel", "chosebest","choseworst", # labeling cols 1-5
                      "trlsnov","cQb","cQe","cQt","cQsa", #cols 6-10
                      "confidence","maxQt","novel_p","nominal_chosen_p","iev_dev", #labeling cols 11-15
                      "rel_iev_max","rel_iev_min","stim_ID"] #labeling cols 16-18
    # converting several of the vars to a float to make them easier to work with
    df_pomdp['trlsnov'] = df_pomdp['trlsnov'].astype('float') 
    df_pomdp['cQb'] = df_pomdp['cQb'].astype('float') 
    df_pomdp['cQe'] = df_pomdp['cQe'].astype('float')
    df_pomdp['cQt'] = df_pomdp['cQt'].astype('float')
    df_pomdp['novel_p'] = df_pomdp['novel_p'].astype('float')
    df_pomdp['iev_dev'] = df_pomdp['iev_dev'].astype('float')
    df_pomdp['rel_iev_max'] = df_pomdp['rel_iev_max'].astype('float')
    df_pomdp['rel_iev_min'] = df_pomdp['rel_iev_min'].astype('float')
    df_pomdp['stim_ID'] = df_pomdp['stim_ID'].astype('float')
    ### merging the data frames and breaking down by run
    df = pd.concat([df,df_pomdp,df_custom], axis=1) # merging the data frames
    # Pulling out the vars I want to save and append for all subs
    df_abbrev = df[["pid","Trial","trlsnov","img1","img1Prob","X1","img2","img2prob","X2","img3","img3prob","X3","chosen_img","chosenovel", "chosebest","choseworst","cQb","cQe","cQt","cQsa","confidence","maxQt",
                    "novel_p","nominal_chosen_p","iev_dev", #labeling cols 11-15
                      "rel_iev_max","rel_iev_min","stim_ID","rewarded","SessChoice.RT","SessChoice.RESP"]]
    # Adding information about novelty
    df_abbrev['img1_novel'] = np.where((df['img1'].shift()!=df['img1']) & (df_abbrev.Trial>1),1,0)
    df_abbrev['img2_novel'] = np.where((df['img2'].shift()!=df['img2']) & (df_abbrev.Trial>1),1,0)
    df_abbrev['img3_novel'] = np.where((df['img3'].shift()!=df['img3']) & (df_abbrev.Trial>1),1,0)
    df_abbrev['is_novel'] = np.where((df_abbrev.img1_novel == 1) | (df_abbrev.img2_novel == 1) | (df_abbrev.img3_novel == 1),1,0)
    # coding trlsnov above 6 as 6 (given their rarity)
    df_abbrev['trlsnov_abbrev'] = np.where(df_abbrev.trlsnov>5, 6,df_abbrev.trlsnov)
    # Adding in the reward value associated with the selected image
    cond = [df_abbrev.chosen_img == df_abbrev.img1,df_abbrev.chosen_img == df_abbrev.img2,df_abbrev.chosen_img == df_abbrev.img3]
    outputs = [df_abbrev.img1Prob,df_abbrev.img2prob,df_abbrev.img3prob]
    df_abbrev['chosen_p'] = np.select(cond,outputs,default=np.nan)
    # Generating a participant summary file
    df_sum = df_abbrev.groupby('trlsnov_abbrev')['chosenovel','chosebest','choseworst'].agg(['count','mean','sem'])
    sum_filename = os.path.join(behave_dir,'summary_out',cursub[0]+'_sum.csv')
    df_sum.to_csv(sum_filename, index=False)
    # Appending the data to get all subs into one file for analysis in R
    df_append = df_append.append(df_abbrev)
# saving all subject file
df_append.to_csv(bandit_alldat_out, index=False)
#%%