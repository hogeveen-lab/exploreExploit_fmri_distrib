#!/bin/bash
# """
# Explore-Exploit fMRI: Neuron Paper
# FEATQUERY template for MODELBASED mean t-stat in a given mask
# notes: For use  in Bayesian Multilevel Model (cf., AFNI's RBA function)

# author: jeremy hogeveen (jhogeveen@unm.edu)
# last edit: March 9, 2022
# """

# setting up the filepaths
base_dir=PATHPATHPATHPATH
fsl_folder=${base_dir}/fsl
out_dir=${base_dir}/data_frames

# which contrast are we interested in?
model="allruns_modelbased"
name=`cut -d_ -f2 <<< $model`
name=${name}v1

# declaring participant $ roi list file
sub_file="PATHPATHPATHPATH/sublist.txt" # list of subjects to be included in model
roi_file="PATHPATHPATHPATH/10b_bmlm_featquery_roilist.txt"

# reading the participant & roi files 
sub_line=`cat $sub_file`
roi_line=`cat $roi_file`

# looping through participants and rois
for p in $sub_line; do
	for r in $roi_line; do
		roi="$(basename -s .nii.gz ${r})"
		echo "#### Extracting ${roi}  data for Subject ${p} ####"
		featq_filepattern=${fsl_folder}/${p}/${model}.gfeat/*/featquery*${roi}*
		for file in ${featq_filepattern}; do
    		# pulling the info I need from the filename
    		dir="$(basename $file)"
			con=`cut -d_ -f2 <<< $dir`
    		# using awk to get the data from the featquery report file
    		response=`awk '{print $6}' $file/report.txt`
            # pulling the square root of the # of voxels
            N=`awk '{print $3}' $file/report.txt`
            square_N=`echo "scale=4; sqrt($N)" | bc`
            # pulling the standard deviation
            sd=`awk '{print $10}' $file/report.txt`
            # calculating the sem
            sem=$(echo "$sd / $square_N" | bc -l )
    		# mega data frame to put it all in
    		out_file=${out_dir}/${name}_${con}.txt
    		# if no file exists, make one
    		if [ ! -f ${out_file} ]; then
        			echo -e "Subj\tROI\tY\tSE" > ${out_file}
        			echo -e "${p}\t${roi}\t${response}\t${sem}" >> ${out_file}
    		else # if it does exist, add to it
        			echo -e "${p}\t${roi}\t${response}\t${sem}" >> ${out_file}
    		fi
		done
	done
done
