#!/usr/bin/env Rscript
# -*- coding: utf-8 -*-
# """
# Explore-Exploit fMRI: Neuron Manuscript
# Code step 3 --> Running behavioral data analysis routine

# author: jeremy hogeveen (jhogeveen@unm.edu)
# last edit: March 9, 2021
# """

#### #### #### #### ####
# Chunk #1: PREAMBLE #
#### #### #### #### ####
# * setting paths
# * loading R packages
# * creating some homemade plotting etc. functions

# misc backend stuff
if(!is.null(dev.list())) dev.off()
rm(list = ls())
cat("\014") 
options(buildtools.check = function(action) TRUE)

### Paths
# base filepath
basefolder <- '#####' # filepath to base directory
# input data for bandit task
bandit_datafolder <- paste(basefolder,'behave',sep='/')
bandit_dataFile <- paste(bandit_datafolder,'alldat_bandit.csv',sep='/')
monkey_dataFile <- paste(bandit_datafolder,'eightmonkeys_novelty_fjh.txt',sep='/')
# input questionnaire data
quest_featq_dataFile <- paste(basefolder,'master_data_file.csv',sep='/')
# set up a potential output folder for saving plots
plotsfolder <- paste(basefolder,'plots',sep = '/')

### Loading some functions
source(paste(basefolder,'bandit_functions.R',sep='/'))

### Reading in the packages I tend to use
source(paste(basefolder,'bandit_packages.R',sep='/'))
mylib()

# monkey and human coefficients
human_mdpfile <- read_csv(paste(basefolder,'model_dat/humanMDPparams.txt',sep='/'))
monkey_mdpfile <- read_csv(paste(basefolder,'model_dat/monkeyMDPparams.txt',sep='/')) %>% rename(Subj_ID="Monkey_ID")

### Setting some misc options
# Custom palette for plotting
my_palette <- c("#0000FF","#3ADF00","#FF0000","#ff7f00","#6a3d9a",
                "#a6cee3","#b2df8a","#fb9a99","#fdbf6f","#cab2d6",
                "#8dd3c7","#bebada","#d9d9d9","#fccde5","#ffffb3")
# Position dodging for interaction plots:
dodge <- position_dodge(1)
# For changing the default font sizes for all plots:
size<-28
theme_set(theme_grey(base_size = size))
# other miscellaneous stuff
select <- dplyr::select # to avoid lme4 overwriting select for dplyr
options(scipen = 999) # to provide precise decimal places rather than exponential notation

#### #### #### #### ####
# Chunk #2: WRANGLING DATA
#### #### #### #### ####
# * reading data in
# * computing some needed vars
# * merging trial-level bandit data with self-report and featquery results
# * computing sample size and some quick demographics

### read in the data
# trialwise bandit data
df_bandit <- read_csv(bandit_dataFile) %>%
  filter(!is.na(chosen_img),!is.na(novel_p)) %>% # removing no-response trials
  rename(RT='SessChoice.RT') %>% # renaming the RT variable to someone more sensible
  mutate(novel_p = ifelse(novel_p==2,0.2,
                          ifelse(novel_p==5,0.5,
                                 ifelse(novel_p==8,0.8,0)))) %>% # recoding the novel stim prob
  mutate(zbon=(cQb-0)/sd(cQb), # bonus scaled to mean=0
         ziev=(cQe-0.5)/sd(cQe), # iev scaled to mean=0.5
         zfev=(cQt-6.55)/sd(cQt))  %>% # fev scaled to mean=6.55
  mutate(dec_type = ifelse(chosenovel==1,'chosenovel',
                           ifelse(chosebest==1,'chosebest',
                                  ifelse(choseworst==1,'choseworst','')))) # coding decision type as chosenovel = 1, chosebest = 2, choseworst = 3
# subject-level questionnaire & featquery (FMRI ROI-level) data
df_otherDat <- read_csv(quest_featq_dataFile) %>%
  rename(Sex=DEMOJH_002) %>% # renaming sex and age vars
  rename(Age=DEMOJH_001)
# merging trialwise and subject-level data
df <- tbl_df(merge(df_bandit,df_otherDat,by='pid'))

### Filtering out participants
# finding participants who were significant outliers relative to the assoc between iev/bonus
df_pomdp_out <- df %>%
  select(pid,iev,bonus) %>%
  distinct() %>%
  mutate(pomdp_zres = abs(rstandard(lm(bonus~iev))), 
         pomdp_out = ifelse(pomdp_zres>2,1,0)) %>%
  select(pid,pomdp_out) # participant #43 was a clear outlier from this perspective
# finding participants who were significant outliers based on their response rate durign the task
df_resp_out <- df %>%
  select(pid,Trial) %>%
  group_by(pid) %>%
  summarise(N=n())
mean_numresp <- mean(df_resp_out$N)
sd_numresp <- sd(df_resp_out$N)
df_resp_out <- df_resp_out %>%
  mutate(resp_out = ifelse(((N-mean_numresp)/sd_numresp)<(-2.5),1,0)) %>%
  select(pid,resp_out) # note: this includes participants 10, 13, and 22 (22 had a response box glitch)
# merging the pomdp and resp outliers into the dataset
df <- full_join(df,df_pomdp_out,by='pid')
df <- full_join(df,df_resp_out,by='pid')
# filtering out bad data
df <- df %>%
  filter(resp_out==0, pomdp_out==0) %>%
  filter(pid!=7,pid!=10,pid!=13) # motion outliers (2 SD above mean FD)

### adding explorer vs. exploiter vs. other groupings
med_iev <- median(df$iev)
med_bon <- median(df$bonus)
df <- df %>%
    mutate(pomdp_grp = ifelse((iev<med_iev) & (bonus>med_bon),'explorers',
                              ifelse((iev>med_iev) & (bonus<med_bon),'exploiters',
                                     'random')))


#### #### #### #### ####
# Chunk 3: demographics
#### #### #### #### ####
# * Creating table of the N, age, sex, etc.
# * Testing whether the IEV-BONUS model params vary as a f(x) of sex, age

### Creating a demographics table
print(df_demo_sum <- df %>%
      select(pid,Age,Sex) %>%
      distinct() %>%
      summarise(N = n(),
                mean_age = mean(Age),
                sd_age = sd(Age),
                num_fem = sum(Sex==2),
                num_male = sum(Sex==1)))

### Plotting POMDP coefficients as a f(x) of afge
df_demo <- df %>%
      select(pid,Age,Sex,iev,bonus) %>%
      distinct() %>%
      pivot_longer(cols = iev:bonus,
                  names_to="model_params",
                  values_to="estimates")
pdf(file=paste(plotsfolder,"pomdp_by_age.pdf",sep='/'))
scatterPlot_int(df_demo,df_demo$Age,df_demo$estimates,df_demo$model_params,"Age (years)","Parameter Estimate")
dev.off()

### testing whether POMDP coefficients are modulated by age
# does age affect choice profile?
m_choice_age_main_std <- lmer(estimates ~ Age + model_params + (1 | pid),df_demo)
m_choice_age_int_std <- lmer(estimates ~ Age * model_params + (1 | pid),df_demo)
m_choice_age_main_rob <- rlmer(estimates ~ Age + model_params + (1 | pid),df_demo)
m_choice_age_int_rob <- rlmer(estimates ~ Age * model_params + (1 | pid),df_demo)
# getting summary data FOR MAIN EFFECTS
summary(m_choice_age_int_rob)
('confidence intervals for choice type main effects rlmer')
confint.rlmerMod(m_choice_age_main_rob)
print('p-values for choice type main effects rlmer')
pvalue.rlmerMod(m_choice_age_int_std,m_choice_age_int_rob)
print('Residuals plots for main effects rlmer')
plot(m_choice_age_int_rob,which=c(1,2))
print('INFERENCE: No modulation of the relationship between IEV/BONUS as a function of Age')

### Plotting POMDO coefficients as a f(x) of sex
pdf(file=paste(plotsfolder,"pomdp_by_sex.pdf",sep='/'))
boxPlot_int(df_demo,as.factor(df_demo$Sex),df_demo$estimates,df_demo$model_params,"Biological Sex","Parameter Estimate")
dev.off()

### testing whether POMDP coefficients are modulated by sex
# does sex affect choice profile?
m_choice_sex_main_std <- lmer(estimates ~ Sex + model_params + (1 | pid),df_demo)
m_choice_sex_int_std <- lmer(estimates ~ Sex * model_params + (1 | pid),df_demo)
m_choice_sex_main_rob <- rlmer(estimates ~ Sex + model_params + (1 | pid),df_demo)
m_choice_sex_int_rob <- rlmer(estimates ~ Sex * model_params + (1 | pid),df_demo)
# getting summary data FOR MAIN EFFECTS
summary(m_choice_sex_int_rob)
('confidence intervals for choice type main effects rlmer')
confint.rlmerMod(m_choice_sex_int_rob)
print('p-values for choice type main effects rlmer')
pvalue.rlmerMod(m_choice_sex_int_std,m_choice_sex_int_rob)
print('Residuals plots for main effects rlmer')
plot(m_choice_sex_int_rob,which=c(1,2))
print('INFERENCE: No modulation of the relationship between IEV/BONUS as a function of Sex.')

#### #### #### #### ####
# Chunk #3: TESTING FOR BANDIT LEARNING EFFECTS
#### #### #### #### ####
# * LMMs on the effect of selecting each option by number of trials since insertion (trlsnov)
# * plotting the learning curves across trlsnov

### Filtering to a performance by trlsnov data frame
df_choice_trlsnov <- df %>%
    group_by(pid,trlsnov_abbrev) %>%
    summarise(N=n(),
              p_chosenovel = sum(chosenovel)/N,
              p_chosebest = sum(chosebest)/N,
              p_choseworst = sum(choseworst)/N)

### Plotting novel, best, and worst as a function of trials since novel
df_performance_plot_means <- df_choice_trlsnov %>%
  group_by(pid,trlsnov_abbrev) %>%
  select(-N) %>%
  group_by(trlsnov_abbrev) %>%
  summarise(N=n(),
            p_chosenovel=mean(p_chosenovel),
            p_chosebest=mean(p_chosebest),
            p_choseworst=mean(p_choseworst)) %>%
  select(-N) %>%
  melt(id.vars='trlsnov_abbrev')
df_performance_plot_sems <- df_choice_trlsnov %>%
  group_by(pid,trlsnov_abbrev) %>%
  select(-N) %>%
  group_by(trlsnov_abbrev) %>%
  summarise(N=n(),
            sem_chosenovel=sd(p_chosenovel)/sqrt(N),
            sem_chosebest=sd(p_chosebest)/sqrt(N),
            sem_choseworst=sd(p_choseworst)/sqrt(N)) %>%
  select(-N) %>%
  melt(id.vars='trlsnov_abbrev')
df_performance_plot_errorbars <- aes(ymax = df_performance_plot_means$value + df_performance_plot_sems$value,
                               ymin=df_performance_plot_means$value - df_performance_plot_sems$value)
novelbestworst_lineplot <- linePlot_int(df_performance_plot_means,df_performance_plot_means$trlsnov_abbrev,df_performance_plot_means$value,df_performance_plot_means$variable,
                                        "Trials since novel","p(choice)",df_performance_plot_errorbars,'Choice Type') + ylim(0,0.9)
# Getting the subject-level data
df_performance_long <- df_choice_trlsnov %>% 
    select(-N) %>% 
    pivot_longer(starts_with('p_'),
                 names_to='condition',
                 values_to='p_choice')
# Plotting data overlay
pdf(file=paste(plotsfolder,"choice_by_trlsnov.pdf",sep='/'))
plot(novelbestworst_lineplot +
     geom_point(data=df_performance_long,aes(x=trlsnov_abbrev,y=p_choice,color=condition),
                shape=16,size=2,pch=4,alpha=0.6,position=position_jitterdodge(dodge.width=0.5))+ guides(color = FALSE, size = FALSE))
dev.off()

### testing the omnibus interaction between choice type and trlsnov in humans
# Simple group comparisons
m_omnibus_std <- lmer(p_choice ~ trlsnov_abbrev*condition + (1 | pid),df_performance_long)
anova(m_omnibus_std)

### testing probability of selecting the novel option as a f(x) of trlsnov
m_chosenovel_std <- lmer(p_chosenovel ~ trlsnov_abbrev + (1 | pid),df_choice_trlsnov)
m_chosenovel_rob <- rlmer(p_chosenovel ~ trlsnov_abbrev + (1 | pid),df_choice_trlsnov)
# getting summary data FOR MAIN EFFECTS
summary(m_chosenovel_rob)
print('confidence intervals for choosing the novel option rlmer')
confint.rlmerMod(m_chosenovel_rob)
print('p-values for choosing the novel option main effects rlmer')
pvalue.rlmerMod(m_chosenovel_std,m_chosenovel_rob)
print('Residuals plots for choosing the novel option effects rlmer')
plot(m_chosenovel_rob,which=c(1,2))
print('INFERENCE: Folks choose the novel option less across time')

### testing probability of selecting the best option as a f(x) of trlsnov
m_chosebest_std <- lmer(p_chosebest ~ trlsnov_abbrev + (1 | pid),df_choice_trlsnov)
m_chosebest_rob <- rlmer(p_chosebest ~ trlsnov_abbrev + (1 | pid),df_choice_trlsnov)
# getting summary data FOR MAIN EFFECTS
summary(m_chosebest_rob)
print('confidence intervals for choosing the best option rlmer')
confint.rlmerMod(m_chosebest_rob)
print('p-values for choosing the best option main effects rlmer')
pvalue.rlmerMod(m_chosebest_std,m_chosebest_rob)
print('Residuals plots for choosing the novel option effects rlmer')
plot(m_chosebest_rob,which=c(1,2))
print('INFERENCE: Folks choose the best option more across time')

#### #### #### #### ####
# Chunk #4: EXPLORE-EXPLOIT ON FIRST TWO TRIALS
#### #### #### #### ####
# * robust rmANOVA contrast between selection of the novel, best, or worst stim on first two trials post-insertion
# * boxplot of the choice behavior on the first two trials post-insertion

### Testing for explore-exploit during first two trials post-novel
# filtering to get an early trials data frame
df_initialTrials <- df %>% 
  group_by(pid) %>% 
  filter(trlsnov<=1) %>%
  summarise(N=n(),
            p_chosenovel=sum(chosenovel)/N,
            p_chosebest=sum(chosebest)/N,
            p_choseworst=sum(choseworst)/N) %>%
  select(-N)
# converting to long for rmanova
df_initialTrials_long <- df_initialTrials %>%
    pivot_longer(starts_with('p_'),
                names_to='dec_type',
                values_to='p_choice')
df_initialTrials_long$dec_type <- factor(df_initialTrials_long$dec_type, levels = c('p_chosenovel','p_chosebest','p_choseworst'))
# Simple group comparisons
rmanovab(df_initialTrials_long$p_choice,df_initialTrials_long$dec_type,df_initialTrials_long$pid,tr=0.2,nboot=2000)
pairdepb(df_initialTrials_long$p_choice,df_initialTrials_long$dec_type,df_initialTrials_long$pid,tr=0.2,nboot=2000)

# computing the means for the early trials by choice type
print(table_initialTrials <- df_initialTrials %>%
  summarise(N=n(),
            mean_chosenovel=mean(p_chosenovel),
            sem_chosenovel=sd(p_chosenovel)/sqrt(N),
            mean_chosebest=mean(p_chosebest),
            sem_chosebest=sd(p_chosebest)/sqrt(N),
            mean_choseworst=mean(p_choseworst),
            sem_choseworst=sd(p_choseworst)/sqrt(N)))
# Plotting the data
pdf(file=paste(plotsfolder,"early_choice_prob.pdf",sep='/'))
plot(boxPlot_main(df_initialTrials_long,df_initialTrials_long$dec_type,df_initialTrials_long$p_choice,df_initialTrials_long$dec_type,
                  "Choice Type","p(choice)"))
dev.off()

#### #### #### #### ####
# Chunk #5: EXPLORE-EXPLOIT LATENCY ON FIRST TWO TRIALS
#### #### #### #### ####
# * robust rmANOVA contrast RT between selection of the novel, best, or worst stim on first two trials post-insertion
# * boxplot of the choice RTs on the first two trials post-insertion

### Testing for explore-exploit latency during first two trials post-novel
# filtering to get an early trials data frame
df_RT_initialTrials <- df %>% 
  group_by(pid,dec_type) %>% 
  filter(trlsnov<=1) %>%
  summarise(mean_rt = mean(RT),
            sd_rt = sd(RT))

df_RT_initialTrials$dec_type <- factor(df_RT_initialTrials$dec_type, levels = c('chosenovel','chosebest','choseworst'))

# Simple group comparisons
rmanovab(df_RT_initialTrials$mean_rt,df_RT_initialTrials$dec_type,df_RT_initialTrials$pid,tr=0.2,nboot=2000)
pairdepb(df_RT_initialTrials$mean_rt,df_RT_initialTrials$dec_type,df_RT_initialTrials$pid,tr=0.2,nboot=2000)

# computing the means for the early trials by choice type
print(table_RT_initialTrials <- df_RT_initialTrials %>%
        group_by(dec_type) %>%
        summarise(N=n(),
                  mean=mean(mean_rt),
                  sem=sd(mean_rt)/sqrt(N)))

# Plotting the data
pdf(file=paste(plotsfolder,"early_choice_latency.pdf",sep='/'))
plot(boxPlot_main(df_RT_initialTrials,df_RT_initialTrials$dec_type,df_RT_initialTrials$mean_rt,df_RT_initialTrials$dec_type,"Choice Type","Mean RT (ms)"))
dev.off()

#### #### #### #### ####
# Chunk #6: Association between POMDP IEV / BONUS parameters WITHIN SUBJECTS
#### #### #### #### ####
# * Running a simple correlation test on trialwise IEV / BONUS parameters within subjects
# * plotting the strength of this association across the sample

### POMDP negative association between IEV and BON within subjects
# running correlation between IEV and BONUS for all subjects
pids <- df %>% select(pid) %>% distinct()
allsub_cors <- data_frame()
for (p in 1:nrow(pids)){
  df_corr <- df %>%
    filter(pid==pids[p,1]$pid) %>%
    select(cQe,cQb)
  m_iev_bon_cor_cursub = cor.test(df_corr$cQb,df_corr$cQe,method='spearman')
  coefficient <- m_iev_bon_cor_cursub$estimate
  allsub_cors <- bind_rows(allsub_cors, m_iev_bon_cor_cursub$estimate)
}

### Merging into a data frame and creating a dummy var for plotting purposes
df_allsub_pomdp_corrs <- tbl_df(cbind(pids,allsub_cors))
df_allsub_pomdp_corrs <- df_allsub_pomdp_corrs %>% mutate(dummy=1)

### Running a t.test of the difference between the correlation values and 0
print(mod_pomdp_iev_bonus_cor <- t.test(df_allsub_pomdp_corrs$rho))
lsr::cohensD(df_allsub_pomdp_corrs$rho)

# Plotting the results of the bayesian one-sample t.test in a boxplot
pdf(file=paste(plotsfolder,"pomdp_within_subs.pdf",sep='/'))
plot(plot_pomdp_iev_bonus_corr <- boxPlot_main(df_allsub_pomdp_corrs,df_allsub_pomdp_corrs$dummy,df_allsub_pomdp_corrs$rho,as.factor(df_allsub_pomdp_corrs$dummy),"All Subjects","IEV-BON Correlation (rho)") + theme(axis.text.x = element_blank(), axis.ticks = element_blank()) + geom_hline(color="red",size=2,yintercept = mod_pomdp_iev_bonus_cor$estimate ) + geom_hline(color="red",size=1,yintercept = mod_pomdp_iev_bonus_cor$conf.int[2],linetype="dashed") + geom_hline(color="red",size=1,yintercept = mod_pomdp_iev_bonus_cor$conf.int[1],linetype="dashed"))
dev.off()

#### #### #### #### ####
## Chunk 7: Correlation between IEV and BONUS parameters BETWEEN SUBJECTS
#### #### #### #### ####
# * Running a simple correlation test on individual differenes in IEV / BONUS between subjects
# * plotting the scatter with a line of best fit

### POMDP negative association between IEV and BON between subjects
# running correlation between IEV and BONUS for all subjects
df_pomdp_params <- df %>% select(pid,iev,bonus) %>% distinct()
# Running a bayesian correlation test of the individual difference params
print(mod_pomdp_iev_bonus_cor_bwsubs <- cor.test(df_pomdp_params$iev,df_pomdp_params$bonus,method='spearman'))

# Plotting the results of the correlation test
pdf(file=paste(plotsfolder,"pomdp_between_subs.pdf",sep='/'))
plot(plot_pomdp_iev_bonus_corr_bwsubs <- scatterPlot_main(df_pomdp_params,df_pomdp_params$iev,df_pomdp_params$bonus,"IEV Parameter","BONUS Parameter"))
dev.off()

#### #### #### #### ####
## Chunk 8: Testing VIF between POMDP params
#### #### #### #### ####
# * using RT as an exemplar outcome var.

### Pulling out a data frame
df_vif <- df %>% 
    mutate(rel_iev = (rel_iev_max+rel_iev_min)/2,
           zrel_iev = scale(rel_iev)) %>%
    select(pid,RT,zbon,ziev,zfev,zrel_iev,trlsnov)

### Testing VIFs in different models
# basic model
mod1_vif <- lmer(RT ~ zbon+ziev+zfev+trlsnov+(1 | pid),df_vif)
print('variance inflation for model including just the basic params (bon, iev, fev)')
car::vif(mod1_vif)

# allvars model
mod2_vif <- lmer(RT ~ zbon+ziev+zrel_iev+zfev+trlsnov+(1 | pid),df_vif)
print('variance inflation for model including all vars of interest')
car::vif(mod2_vif)

# rel_iev model
mod3_vif <- lmer(RT ~ zbon+zrel_iev+zfev+trlsnov+(1 | pid),df_vif)
print('variance inflation for model including rel iev in lieu of iev')
car::vif(mod3_vif)

#### #### #### #### ####
# Chunk #9: TESTING FOR BANDIT LEARNING EFFECTS -- MONKEY
#### #### #### #### ####
# * reading in the monkey darta
# * LMMs on the effect of selecting each option by number of trials since insertion (trlsnov)
# * plotting the learning curves across trlsnov

### Reading in the macaque trial-level
# trialwise bandit data
df_monkey <- read_tsv(monkey_dataFile,col_names = c('pid','trlsnov','trials','choice','reward','chosebest','choseworst','chosenovel')) %>%
  mutate(trlsnov_abbrev=ifelse(trlsnov>=20,20,trlsnov))

### Filtering to a performance by trlsnov data frame
df_choice_trlsnov_monkey <- df_monkey %>%
  group_by(pid,trlsnov_abbrev) %>%
  summarise(N=n(),
            p_chosenovel = sum(chosenovel)/N,
            p_chosebest = sum(chosebest)/N,
            p_choseworst = sum(choseworst)/N)

### Plotting novel, best, and worst as a function of trials since novel
df_performance_plot_means_monkey <- df_choice_trlsnov_monkey %>%
  group_by(pid,trlsnov_abbrev) %>%
  select(-N) %>%
  group_by(trlsnov_abbrev) %>%
  summarise(N=n(),
            p_chosenovel=mean(p_chosenovel),
            p_chosebest=mean(p_chosebest),
            p_choseworst=mean(p_choseworst)) %>%
  select(-N) %>%
  melt(id.vars='trlsnov_abbrev')
df_performance_plot_sems_monkey <- df_choice_trlsnov_monkey %>%
  group_by(pid,trlsnov_abbrev) %>%
  select(-N) %>%
  group_by(trlsnov_abbrev) %>%
  summarise(N=n(),
            sem_chosenovel=sd(p_chosenovel)/sqrt(N),
            sem_chosebest=sd(p_chosebest)/sqrt(N),
            sem_choseworst=sd(p_choseworst)/sqrt(N)) %>%
  select(-N) %>%
  melt(id.vars='trlsnov_abbrev')
df_performance_plot_errorbars_monkey <- aes(ymax = df_performance_plot_means_monkey$value + df_performance_plot_sems_monkey$value,
                                     ymin=df_performance_plot_means_monkey$value - df_performance_plot_sems_monkey$value)
novelbestworst_lineplot_monkey <- linePlot_int(df_performance_plot_means_monkey,df_performance_plot_means_monkey$trlsnov_abbrev,df_performance_plot_means_monkey$value,df_performance_plot_means_monkey$variable,
                                        "Trials since novel","p(choice)",df_performance_plot_errorbars_monkey,'Choice Type') + ylim(-0.05,0.9)
# Getting the subject-level data
df_performance_long_monkey <- df_choice_trlsnov_monkey %>% 
  select(-N) %>% 
  pivot_longer(starts_with('p_'),
               names_to='condition',
               values_to='p_choice')
# Plotting data overlay
pdf(file=paste(plotsfolder,"choice_by_trlsnov_monkey.pdf",sep='/'))
plot(novelbestworst_lineplot_monkey +
       geom_point(data=df_performance_long_monkey,aes(x=trlsnov_abbrev,y=p_choice,color=condition),
                  shape=16,size=2,pch=4,alpha=0.3,position=position_jitterdodge(dodge.width=0.5))+ guides(color = FALSE, size = FALSE))
dev.off()

### testing the omnibus interaction between choice type and trlsnov in humans
# Simple group comparisons
m_omnibus_std_monkey <- lmer(p_choice ~ trlsnov_abbrev*condition + (1 | pid),df_performance_long_monkey)
anova(m_omnibus_std_monkey)

### testing probability of selecting the novel option as a f(x) of trlsnov
m_chosenovel_std_monkey <- lmer(p_chosenovel ~ trlsnov_abbrev + (1 | pid),df_choice_trlsnov_monkey)
m_chosenovel_rob_monkey <- rlmer(p_chosenovel ~ trlsnov_abbrev + (1 | pid),df_choice_trlsnov_monkey)
# getting summary data FOR MAIN EFFECTS
summary(m_chosenovel_rob_monkey)
print('confidence intervals for choosing the novel option rlmer')
confint.rlmerMod(m_chosenovel_rob_monkey)
print('p-values for choosing the novel option main effects rlmer')
pvalue.rlmerMod(m_chosenovel_std_monkey,m_chosenovel_rob_monkey)
print('Residuals plots for choosing the novel option effects rlmer')
plot(m_chosenovel_rob_monkey,which=c(1,2))
print('INFERENCE: Folks choose the novel option less across time')

### testing probability of selecting the best option as a f(x) of trlsnov
m_chosebest_std_monkey  <- lmer(p_chosebest ~ trlsnov_abbrev + (1 | pid),df_choice_trlsnov_monkey)
m_chosebest_rob_monkey  <- rlmer(p_chosebest ~ trlsnov_abbrev + (1 | pid),df_choice_trlsnov_monkey)
# getting summary data FOR MAIN EFFECTS
summary(m_chosebest_rob_monkey)
print('confidence intervals for choosing the best option rlmer')
confint.rlmerMod(m_chosebest_rob_monkey)
print('p-values for choosing the best option main effects rlmer')
pvalue.rlmerMod(m_chosebest_std_monkey,m_chosebest_rob_monkey)
print('Residuals plots for choosing the novel option effects rlmer')
plot(m_chosebest_rob_monkey,which=c(1,2))
print('INFERENCE: Folks choose the best option more across time')

### Plotting novel, best, and worst as a function of trials since novel
df_performance_plot_means_monkey <- df_choice_trlsnov_monkey %>%
  group_by(pid,trlsnov_abbrev) %>%
  select(-N) %>%
  group_by(trlsnov_abbrev) %>%
  summarise(N=n(),
            p_chosenovel=mean(p_chosenovel),
            p_chosebest=mean(p_chosebest),
            p_choseworst=mean(p_choseworst)) %>%
  select(-N) %>%
  melt(id.vars='trlsnov_abbrev')
df_performance_plot_sems_monkey <- df_choice_trlsnov_monkey %>%
  group_by(pid,trlsnov_abbrev) %>%
  select(-N) %>%
  group_by(trlsnov_abbrev) %>%
  summarise(N=n(),
            sem_chosenovel=sd(p_chosenovel)/sqrt(N),
            sem_chosebest=sd(p_chosebest)/sqrt(N),
            sem_choseworst=sd(p_choseworst)/sqrt(N)) %>%
  select(-N) %>%
  melt(id.vars='trlsnov_abbrev')
df_performance_plot_errorbars_monkey <- aes(ymax = df_performance_plot_means_monkey$value + df_performance_plot_sems_monkey$value,
                                            ymin=df_performance_plot_means_monkey$value - df_performance_plot_sems_monkey$value)
novelbestworst_lineplot_monkey <- linePlot_int(df_performance_plot_means_monkey,df_performance_plot_means_monkey$trlsnov_abbrev,df_performance_plot_means_monkey$value,df_performance_plot_means_monkey$variable,
                                               "Trials since novel","p(choice)",df_performance_plot_errorbars_monkey,'Choice Type') + ylim(-0.05,1)
# Getting the subject-level data
df_performance_long_monkey <- df_choice_trlsnov_monkey %>%
  select(-N) %>%
  pivot_longer(starts_with('p_'),
               names_to='condition',
               values_to='p_choice')
# Plotting data overlay
pdf(file=paste(plotsfolder,"choice_by_trlsnov_monkey.pdf",sep='/'))
plot(novelbestworst_lineplot_monkey +
       geom_point(data=df_performance_long_monkey,aes(x=trlsnov_abbrev,y=p_choice,color=condition),
                  shape=16,size=2,pch=4,alpha=0.6,position=position_jitterdodge(dodge.width=0.5))+ guides(color = FALSE, size = FALSE))
dev.off()

### Testing for explore-exploit during first two trials post-novel
# filtering to get an early trials data frame
df_initialTrials_monkey <- df_monkey %>%
  group_by(pid) %>%
  filter(trlsnov<6) %>%
  summarise(N=n(),
            p_chosenovel=sum(chosenovel)/N,
            p_chosebest=sum(chosebest)/N,
            p_choseworst=sum(choseworst)/N) %>%
  select(-N)
# converting to long for rmanova
df_initialTrials_long_monkey <- df_initialTrials_monkey %>%
  pivot_longer(starts_with('p_'),
               names_to='dec_type',
               values_to='p_choice')
df_initialTrials_long_monkey$dec_type <- factor(df_initialTrials_long_monkey$dec_type, levels = c('p_chosenovel','p_chosebest','p_choseworst'))
# Simple group comparisons
print(monkey_earlyTrialsANOVA <- rmanovab(df_initialTrials_long_monkey$p_choice,df_initialTrials_long_monkey$dec_type,df_initialTrials_long_monkey$pid,tr=0.2,nboot=2000))
print(monkey_novbest <- yuend(df_initialTrials_monkey$p_chosenovel,df_initialTrials_monkey$p_chosebest))
print(monkey_bestworst <- yuend(df_initialTrials_monkey$p_chosebest,df_initialTrials_monkey$p_choseworst))

# computing the means for the early trials by choice type
print(table_initialTrials_monkey <- df_initialTrials_monkey %>%
        summarise(N=n(),
                  mean_chosenovel=mean(p_chosenovel),
                  sem_chosenovel=sd(p_chosenovel)/sqrt(N),
                  mean_chosebest=mean(p_chosebest),
                  sem_chosebest=sd(p_chosebest)/sqrt(N),
                  mean_choseworst=mean(p_choseworst),
                  sem_choseworst=sd(p_choseworst)/sqrt(N)))
# Plotting the data
pdf(file=paste(plotsfolder,"early_choice_prob_monkey.pdf",sep='/'))
plot(boxPlot_main(df_initialTrials_long_monkey,df_initialTrials_long_monkey$dec_type,df_initialTrials_long_monkey$p_choice,df_initialTrials_long_monkey$dec_type,
                  "Choice Type","p(choice)"))
dev.off()


#### #### #### #### ####
# Chunk #10: GENERATING ADDTIONAL POMDP PLOTS FOR IEV AND BONUS
#### #### #### #### ####
# * coefficient correlation plotted by species
# * trialwise POMDP ~ normative plot akin to Figure S2 from VInny's 2019 paper

### wrangling dfs
human_mdpfile <- human_mdpfile %>% mutate(species='human') %>% filter(Subj_ID!=43)
monkey_mdpfile <- monkey_mdpfile %>% mutate(species='monkey')
allspecies_df <- rbind(human_mdpfile,monkey_mdpfile)

### estimating correlation strengths
plot(bayes.cor.test(human_mdpfile$IEV_beta,human_mdpfile$BONUS_beta))
plot(bayes.cor.test(monkey_mdpfile$IEV_beta,monkey_mdpfile$BONUS_beta))

### plotting IEV and BONUS coefficients by species
# scatterPlot_int(allspecies_df,allspecies_df$IEV_beta,allspecies_df$BONUS_beta,allspecies_df$species,"IEV Coefficient","Exploration BONUS Coefficient") +
#   scale_color_manual(values=c('#dfc27d','#404040')) + scale_fill_manual(values=c('#dfc27d','#404040'))
ggplot(allspecies_df, aes(x = IEV_beta, y = BONUS_beta, fill = species)) +
  geom_smooth(method=lm,   # Add linear regression line
              se=TRUE,
              size = 0.5,
              linetype="dashed",
              alpha=0.7) +
  geom_point(size=4,colour="black",pch=21) +
  xlab('IEV Coefficient') +
  ylab('BONUS Coefficient') +
  my_theme() +
  scale_fill_manual(values=c('#dfc27d','#404040'))


### gfenerating a summary data frame with mean
df_trialwise_iev_mean <- df  %>%
  mutate(nominal = ifelse(nominal_chosen_p==1,0.2,ifelse(nominal_chosen_p==2,0.5,ifelse(nominal_chosen_p==3,0.8,0))),
         explore_exploit = ifelse(chosenovel==1 & chosebest==0, 'explore', ifelse(chosenovel == 0 & chosebest == 1, 'exploit','garbage'))) %>%
  filter(explore_exploit!='garbage') %>%
  select(trlsnov_abbrev,nominal,explore_exploit,cQe) %>%
  group_by(trlsnov_abbrev,nominal,explore_exploit) %>%
  summarise(iev = mean(cQe))
df_trialwise_iev_mean_explore <- df_trialwise_iev_mean %>% filter(explore_exploit=='explore')
df_trialwise_iev_mean_exploit <- df_trialwise_iev_mean %>% filter(explore_exploit=='exploit')
df_trialwise_bonus_mean <- df  %>%
  mutate(nominal = ifelse(nominal_chosen_p==1,0.2,ifelse(nominal_chosen_p==2,0.5,ifelse(nominal_chosen_p==3,0.8,0))),
         explore_exploit = ifelse(chosenovel==1 & chosebest==0, 'explore', ifelse(chosenovel == 0 & chosebest == 1, 'exploit','garbage'))) %>%
  filter(explore_exploit!='garbage') %>%
  select(trlsnov_abbrev,nominal,explore_exploit,cQb) %>%
  group_by(trlsnov_abbrev,nominal,explore_exploit) %>%
  summarise(bonus = mean(cQb))
df_trialwise_bonus_mean_explore <- df_trialwise_bonus_mean %>% filter(explore_exploit=='explore')
df_trialwise_bonus_mean_exploit <- df_trialwise_bonus_mean %>% filter(explore_exploit=='exploit')
  
### gfenerating a summary data frame with mean
df_trialwise_iev_sem <- df %>%
  mutate(nominal = ifelse(nominal_chosen_p==1,0.2,ifelse(nominal_chosen_p==2,0.5,ifelse(nominal_chosen_p==3,0.8,0))),
         explore_exploit = ifelse(chosenovel==1 & chosebest==0, 'explore', ifelse(chosenovel == 0 & chosebest == 1, 'exploit','garbage'))) %>%
  filter(explore_exploit!='garbage') %>%
  select(trlsnov_abbrev,nominal,explore_exploit,cQe) %>%
  group_by(trlsnov_abbrev,nominal,explore_exploit) %>%
  summarise(N=n(),iev = sd(cQe)/sqrt(N)) %>%
  select(-N)
df_trialwise_iev_sem_explore <- df_trialwise_iev_sem %>% filter(explore_exploit=='explore')
df_trialwise_iev_sem_exploit <- df_trialwise_iev_sem %>% filter(explore_exploit=='exploit')
df_trialwise_bonus_sem <- df %>%
  mutate(nominal = ifelse(nominal_chosen_p==1,0.2,ifelse(nominal_chosen_p==2,0.5,ifelse(nominal_chosen_p==3,0.8,0))),
         explore_exploit = ifelse(chosenovel==1 & chosebest==0, 'explore', ifelse(chosenovel == 0 & chosebest == 1, 'exploit','garbage'))) %>%
  filter(explore_exploit!='garbage') %>%
  select(trlsnov_abbrev,nominal,explore_exploit,cQb) %>%
  group_by(trlsnov_abbrev,nominal,explore_exploit) %>%
  summarise(N=n(),bonus = sd(cQb)/sqrt(N)) %>%
  select(-N)
df_trialwise_bonus_sem_explore <- df_trialwise_bonus_sem %>% filter(explore_exploit=='explore')
df_trialwise_bonus_sem_exploit <- df_trialwise_bonus_sem %>% filter(explore_exploit=='exploit')

### Generating exploration BONUS by explore-exploit and time.
size = 18
# plotting exploration bonus on exploratory choice trials
df_bonus_exploration_bytrials_errorbars <- aes(ymax = df_trialwise_bonus_mean_explore$bonus + df_trialwise_bonus_sem_explore$bonus,
                                     ymin=df_trialwise_bonus_mean_explore$bonus - df_trialwise_bonus_sem_explore$bonus)

bonus_exploration_plot <- ggplot(df_trialwise_bonus_mean_explore, aes(x = as.numeric(trlsnov_abbrev), y = bonus, color = as.factor(nominal))) +
  geom_line(size=1.5) +
  geom_errorbar(df_bonus_exploration_bytrials_errorbars, width=0.1, size=0.5) +
  xlab('Trials since novel') +
  ylab('BONUS') +
  my_theme() +
  scale_color_manual(values=c('#9e9ac8','#6a51a3','#3f007d'))

# plotting exploration bonus on exploitative choice trials
df_bonus_exploitation_bytrials_errorbars <- aes(ymax = df_trialwise_bonus_mean_exploit$bonus + df_trialwise_bonus_sem_exploit$bonus,
                                               ymin=df_trialwise_bonus_mean_exploit$bonus - df_trialwise_bonus_sem_exploit$bonus)

bonus_exploitation_plot <- ggplot(df_trialwise_bonus_mean_exploit, aes(x = as.numeric(trlsnov_abbrev), y = bonus, color = as.factor(nominal))) +
  geom_line(size=1.5) +
  geom_errorbar(df_bonus_exploitation_bytrials_errorbars, width=0.1, size=0.5) +
  xlab('Trials since novel') +
  ylab('BONUS') +
  my_theme() +
  scale_color_manual(values=c('#9e9ac8','#6a51a3','#3f007d'))

grid.arrange(bonus_exploration_plot,bonus_exploitation_plot)

### Generating IEV plot by explore-exploit and time.

# plotting iev on exploratory choice trials
df_iev_exploration_bytrials_errorbars <- aes(ymax = df_trialwise_iev_mean_explore$iev + df_trialwise_iev_sem_explore$iev,
                                               ymin=df_trialwise_iev_mean_explore$iev - df_trialwise_iev_sem_explore$iev)

iev_exploration_plot <- ggplot(df_trialwise_iev_mean_explore, aes(x = as.numeric(trlsnov_abbrev), y = iev, color = as.factor(nominal))) +
  geom_line(size=1.5) +
  geom_errorbar(df_iev_exploration_bytrials_errorbars, width=0.1, size=0.5) +
  xlab('Trials since novel') +
  ylab('IEV') +
  my_theme() +
  scale_color_manual(values=c('#9e9ac8','#6a51a3','#3f007d')) 

# plotting iev on exploitative choice trials
df_iev_exploitation_bytrials_errorbars <- aes(ymax = df_trialwise_iev_mean_exploit$iev + df_trialwise_iev_sem_exploit$iev,
                                                ymin=df_trialwise_iev_mean_exploit$iev - df_trialwise_iev_sem_exploit$iev)

iev_exploitation_plot <- ggplot(df_trialwise_iev_mean_exploit, aes(x = as.numeric(trlsnov_abbrev), y = iev, color = as.factor(nominal))) +
  geom_line(size=1.5) +
  geom_errorbar(df_iev_exploitation_bytrials_errorbars, width=0.1, size=0.5) +
  xlab('Trials since novel') +
  ylab('IEV') +
  my_theme() +
  scale_color_manual(values=c('#9e9ac8','#6a51a3','#3f007d')) 

grid.arrange(iev_exploration_plot,iev_exploitation_plot)

           
           